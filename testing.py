import pandas as pd
import pytest
import numpy as np
from scipy import sparse
from build_graphs import load_data,compute_graph,write_hypergraph,load_graph
from build_communities import partition_core,simplify_community_struct
from DIRS import TEST_PATH

def generating_path() -> (str, pd.Timestamp):
    """
    Function to generate a path and a deadline timestamp.

    Returns:
        Tuple[str, pd.Timestamp]: A tuple containing the path (str) and the deadline (pd.Timestamp).
    """
    path=TEST_PATH
    deadline=pd.Timestamp("2021-06-01" + "T00:00:00+02")
    return path,deadline

def generating_simple_case() -> pd.DataFrame:
    """
    Function to generate a simple test dataset for connected component analysis.

    Returns:
        pd.DataFrame: A DataFrame containing the generated dataset.
    """
    #BUILDING AN EXAMPLE DATASET TO TEST THE CONNECTED COMPONENT ANALYSIS
    id=["0","1","2","3"]
    hyperlink=["0","1","2","3"]
    source=["3","0","1","2"]
    target=["1","2","3","0"]
    dict={"id":id,"source":source,"hyperlink":hyperlink,"target":target}
    retweet_simple=pd.DataFrame(dict)
    retweet_simple.set_index("id")
    return retweet_simple
    
def generate_simple_adj() -> (sparse.coo_matrix, sparse.coo_matrix):
    """
    Function to generate a simple adjacency matrix and an identity matrix.

    Returns:
        Tuple[sparse.coo_matrix, sparse.coo_matrix]: A tuple containing the adjacency matrix and the identity matrix.
    """
    x=[1,0,3,2,3,0]
    y_=[0,1,2,3,0,3]
    y=[0,1,2,3]
    adj=sparse.coo_matrix((np.ones(6),(x,y_)),shape=(4,4))
    id=sparse.coo_matrix((np.ones(4),(y,y)),shape=(4,4))
    return adj,id
########## TEST FUNCTIONS ##########
def test_load_data():
    """
    Test function for loading data.

    GIVEN: a path and a deadline timestamp generated by the function generating_path().
    WHEN: loading data using load_data() function.
    THEN: the function should return a pandas DataFrame.
    """

    path,deadline=generating_path()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path)
    assert isinstance(df, pd.DataFrame)


def test_compute_graph():
    """
    Test function for computing a graph.

    GIVEN: A DataFrame loaded from a CSV file using load_data().
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with the same number of nodes as the 'retweeted_status.id'
          column in the DataFrame after dropping NA values.
    """

    path,deadline=generating_path()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path)
    assert len(compute_graph(df))==len(df["retweeted_status.id"].dropna())


def test_write_hypergraph_user():
    """
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a pandas Series for user_ids.
    """

    path,deadline=generating_path()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(users,pd.Series)

def test_write_hypergraph_matrix():
"""
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a sparse csr_matrix for the adjancy matrix.
    """
    path,deadline=generating_path()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(matrix,sparse.csr_matrix)


def test_write_hypergraph_simple_case():
    def test_write_hypergraph_simple_case():
    """
    Test function for writing hypergraph with a simple case.

    GIVEN: a simple test dataset generated by the function generating_simple_case().
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: The risult has the signature (2,2).
    """

    retweet_simple=generating_simple_case()
    deadline=''
    matrix,users=write_hypergraph(retweet_simple,deadline,write=False)
    assert matrix.shape==(2,2)

def test_partition_core_type():
    """
    Test function for partitioning core with type checking.

    GIVEN: a graph loaded using load_graph().
    WHEN: partitioning core using partition_core() function.
    THEN: the function should return a pandas Series.
    """

    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    assert isinstance(partition_core(tail,head,usermap),pd.Series)
    assert isinstance(partition_core(tail,head,usermap,kind="leiden"),pd.Series)

def test_partition_core_simple_case_louvain():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with louvain algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3])).unique())==2
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2

def test_partition_core_simple_case_leiden():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with leiden algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2


def test_simplify_community_struct_size_lv():
    """
    Test function for simplifying community structure by size with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap),comm_size=50)
    assert (i<51 for i in simplified_com.value_counts().sort_values(ascending=False))

def test_simplify_community_struct_size_ld():
    """
    Test function for simplifying community structure by size with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap,kind="leiden"),comm_size=50)
    assert (i<51 for i in simplified_com.value_counts().sort_values(ascending=False))

def test_simplify_community_coverage_lv_40():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """

    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage=0.4)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>0.39)

def test_simplify_community_coverage_ld_40():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """
    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage=0.4)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>0.39)

def test_simplify_community_coverage_lv_90():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage=0.9)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>0.89)

def test_simplify_community_coverage_ld_90():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline=generating_path()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage=0.9)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>0.89)