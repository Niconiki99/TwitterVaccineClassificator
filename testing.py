import pandas as pd
import pytest
import numpy as np
import pathlib
from scipy import sparse
from build_graphs import load_data,compute_graph,write_hypergraph,load_graph
from build_communities import partition_core,simplify_community_struct
from configobj import ConfigObj 

def generate_metadata_full() -> (str, pd.Timestamp,dict):
    """
    Function to generate metadatas for the reading.

    Returns:
        Tuple[str, pd.Timestamp]: A tuple containing the path (str) and the deadline (pd.Timestamp) and the types of the columns (dict).
    """
    config= ConfigObj("config.txt")
    path=config["DIRS"]["TEST_PATH"]
    deadline=pd.Timestamp("2021-06-01" + "T00:00:00+02")
    dtype=config["READING_PARAMS"]["DF_FULL"]["dtype_df"]
    return path,deadline,dtype
    
def generating_metadata_example() -> (str, pd.Timestamp,dict):
    """
    Function to generate metadatas for the reading of exaples.

    Returns:
        Tuple[str, pd.Timestamp]: A tuple containing the path (str) and the deadline (pd.Timestamp) and the types of the columns (dict).
    """
    config= ConfigObj("config.txt")
    path=config["DIRS"]["TEST_PATH"]
    deadline=pd.Timestamp("2021-06-01" + "T00:00:00+02")
    dtype=config["READING_PARAMS"]["DF_FULL"]["dtype_example"]
    return path,deadline,dtype


def generating_simple_case() -> pd.DataFrame:
    """
    Function to generate a simple test dataset for connected component analysis.

    Returns:
        pd.DataFrame: A DataFrame containing the generated dataset.
    """
    #BUILDING AN EXAMPLE DATASET TO TEST THE CONNECTED COMPONENT ANALYSIS
    id=["0","1","2","3"]
    hyperlink=["0","1","2","3"]
    source=["3","0","1","2"]
    target=["1","2","3","0"]
    dict={"id":id,"source":source,"hyperlink":hyperlink,"target":target}
    retweet_simple=pd.DataFrame(dict)
    retweet_simple.set_index("id")
    return retweet_simple
    
def generate_simple_adj() -> (sparse.coo_matrix, sparse.coo_matrix):
    """
    Function to generate a simple adjacency matrix and an identity matrix.

    Returns:
        Tuple[sparse.coo_matrix, sparse.coo_matrix]: A tuple containing the adjacency matrix and the identity matrix.
    """
    x=[1,0,3,2,3,0]
    y_=[0,1,2,3,0,3]
    y=[0,1,2,3]
    adj=sparse.coo_matrix((np.ones(6),(x,y_)),shape=(4,4))
    id=sparse.coo_matrix((np.ones(4),(y,y)),shape=(4,4))
    return adj,id
########## TEST FUNCTIONS ##########
######################################################
#GENERAL FUNCTIONS#
######################################################

def test_load_data():
    """
    Test function for loading data.

    GIVEN: a path and a deadline timestamp generated by the function generate_metadata_full().
    WHEN: loading data using load_data() function.
    THEN: the function should return a pandas DataFrame.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path,dtype)
    assert isinstance(df, pd.DataFrame)


def test_compute_graph():
    """
    Test function for computing a graph.

    GIVEN: A DataFrame loaded from a CSV file using load_data().
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with the same number of nodes as the 'retweeted_status.id'
          column in the DataFrame after dropping NA values.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path,dtype)
    assert len(compute_graph(df))==len(df["retweeted_status.id"].dropna())


def test_write_hypergraph_user():
    """
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a pandas Series for user_ids.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path,dtype))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(users,pd.Series)

def test_write_hypergraph_matrix():
    """
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a sparse csr_matrix for the adjancy matrix.
    """
    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path,dtype))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(matrix,sparse.csr_matrix)

######################################################
#SIMPLE CASE#
######################################################

def test_write_hypergraph_simple_case():
    """
    Test function for writing hypergraph with a simple case.

    GIVEN: a simple test dataset generated by the function generating_simple_case().
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: The risult has the signature (2,2).
    """

    retweet_simple=generating_simple_case()
    deadline=''
    matrix,users=write_hypergraph(retweet_simple,deadline,write=False)
    assert matrix.shape==(2,2)

def test_partition_core_type():
    """
    Test function for partitioning core with type checking.

    GIVEN: a graph loaded using load_graph().
    WHEN: partitioning core using partition_core() function.
    THEN: the function should return a pandas Series.
    """

    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    assert isinstance(partition_core(tail,head,usermap),pd.Series)
    assert isinstance(partition_core(tail,head,usermap,kind="leiden"),pd.Series)

def test_partition_core_simple_case_louvain():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with louvain algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3])).unique())==2
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2

def test_partition_core_simple_case_leiden():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with leiden algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2


def test_simplify_community_struct_size_lv():
    """
    Test function for simplifying community structure by size with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    comm_size=50
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap),comm_size)
    for i in simplified_com.value_counts().sort_values(ascending=False):
        assert (i>=comm_size+1)

def test_simplify_community_struct_size_ld():
    """
    Test function for simplifying community structure by size with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    comm_size=50
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap,kind="leiden"),comm_size)
    for i in simplified_com.value_counts().sort_values(ascending=False):
        assert (i>=comm_size+1)

def test_simplify_community_coverage_lv_40():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """
    coverage=0.4
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_ld_40():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """
    coverage=0.4
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_lv_90():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline,dtype=generate_metadata_full()
    coverage=0.9
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_ld_90():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline,dtype=generate_metadata_full()
    coverage=0.9
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)
######################################################
#CONNECTED GRAPH CASE#
######################################################
    
def test_connected_comp_graph():
    """
    Test function for computing a graph in a connected toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df).astype(int)
    expected_source=[0,0,0,0,0,1,1,2,2,3,3,3]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11]
    expected_target=[1,2,3,1,2,3,2,1,0,0,1,2]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i])
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])


def test_connected_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for connected nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_con_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_load_graph_connected():
    """
    Test function for loading a connected graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix and usermap.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    savenames=[pathlib.Path("connected/connected_head.npz"),
               pathlib.Path("connected/connected_tail.npz"),
               pathlib.Path("connected/connected_usermap.csv.gz")]
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    tail, head, usermap = load_graph(deadline,path,savenames)
    adj_trasp=tail @ (head.transpose())
    for i in range(len(users)):
        for j in range(len(users)):
            assert (adj_trasp.toarray()[int(usermap[i]),int(usermap[i])]==adj.toarray()[int(users[i]),int(users[i])])

def test_partition_louvain_connected():
    """
    Test function for partitioning a connected graph with Louvain algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("connected/connected_head.npz"),
               pathlib.Path("connected/connected_tail.npz"),
               pathlib.Path("connected/connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in results:
        assert (i==0)

def test_partition_leiden_connected():
    """
    Test function for partitioning a connected graph with Leiden algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("connected/connected_head.npz"),
               pathlib.Path("connected/connected_tail.npz"),
               pathlib.Path("connected/connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in results:
        assert (i==0)

######################################################
#DIRECTED COMPLETELY CONNECTED CASE#
######################################################

def test_comp_connected_comp_graph():
    """
    Test function for computing a graph in a completely connected toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df).astype(int)
    expected_source=[0,0,0,1,1,1,2,2,2,3,3,3]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11]
    expected_target=[1,2,3,0,2,3,0,1,3,0,1,2]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i] )
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])

def test_comp_connected_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for completly connected nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_comp_con_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_load_graph_comp_connected():
    """
    Test function for loading a completly connected graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("compleately_connected/comp_connected_head.npz"),
               pathlib.Path("compleately_connected/comp_connected_tail.npz"),
               pathlib.Path("compleately_connected/comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=(tail @ (head.transpose())).data
    adj_res=adj.data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_symmetry_comp_con():
    """
    Test symmetry of the adjacency matrix in the case of a bidirectional completely connected graph.

    GIVEN: A bidirectional completely connected graph.
    WHEN: Computing the adjacency matrix.
    THEN: The matrix should be equal to the transposed matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    adj_test=adj.data
    adj_res=adj.transpose().data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_comp_con_is_completely_connected():
    """
    Test if the adjacency matrix satisfies proprierty of a completely connected graph.

    GIVEN: A bidirectional completely connected graph.
    WHEN: Computing the adjacency matrix.
    THEN: The matrix should has exactly n(n-1) links (because each node links as a source and as a target with all the users).
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    n=len(users)
    assert (np.sum(adj.data)==(n*(n-1)))

def test_partition_louvain_comp_connected():
    """
    Test function for partitioning a completly connected graph with Louvain algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("compleately_connected/comp_connected_head.npz"),
               pathlib.Path("compleately_connected/comp_connected_tail.npz"),
               pathlib.Path("compleately_connected/comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in results:
        assert (i==0)


def test_partition_leiden_comp_connected():
    """
    Test function for partitioning a connected graph with Leiden algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("compleately_connected/comp_connected_head.npz"),
               pathlib.Path("compleately_connected/comp_connected_tail.npz"),
               pathlib.Path("compleately_connected/comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in results:
        assert (i==0)
        
######################################################
#UNDIRECTED COMPLETELY CONNECTED CASE#
######################################################

def test_comp_connected_undir_comp_graph():
    """
    Test function for computing a graph in a undirected completely connected toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/undirected_compleately_connected/undir_comp_con.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    retweets=retweets.astype(int)
    expected_source=[1,0,0,1,1,2]
    expected_hyperlink=[0,1,2,3,4,5]
    expected_target=[0,2,3,2,3,3]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i])
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])

def test_undir_comp_con_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for undirected completly connected nodess.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/undirected_compleately_connected/undir_comp_con.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_undir_comp_con_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/undirected_compleately_connected/undir_comp_con.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_load_graph_undir_comp_con():
    """
    Test function for loading a completly connected graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the undirected compleatly connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/undirected_compleately_connected/undir_comp_con.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("undirected_compleately_connected/undir_comp_con_head.npz"),
               pathlib.Path("undirected_compleately_connected/undir_comp_con_tail.npz"),
               pathlib.Path("undirected_compleately_connected/undir_comp_con_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=(tail @ (head.transpose())).data
    adj_res=adj.data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_upp_triang_undir_comp_con():
    """
    Test that the adjacency matrix in the case of a bidirectional completely connected graph is upper triangular.

    GIVEN: An undirected completely connected graph.
    WHEN: Computing the adjacency matrix.
    THEN: The matrix + its transpose should be equal to the transposed sum matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/compleately_connected/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    adj_sum=adj+adj.transpose()
    adj_test=adj_sum.data
    adj_res=adj_sum.transpose().data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_undir_comp_con_is_completely_connected():
    """
    Test if the adjacency matrix satisfies the properties of a completely connected graph.

    GIVEN: A bidirectional completely connected graph.
    WHEN: Computing the adjacency matrix.
    THEN: The matrix should have exactly n(n-1)/2 links (because each node links as a source and target with all the users).
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/undirected_compleately_connected/undir_comp_con.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    n=len(users)
    assert (np.sum(adj.data)==(n*(n-1))//2)

def test_partition_undir_leiden_comp_connected():
    """
    Test function for partitioning a connected graph with Leiden algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("undirected_compleately_connected/undir_comp_con_head.npz"),
               pathlib.Path("undirected_compleately_connected/undir_comp_con_tail.npz"),
               pathlib.Path("undirected_compleately_connected/undir_comp_con_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in results:
        assert (i==0)

######################################################
#TWO ISLANDS CASE#
###################################################### 

def test_two_islands_comp_graph():
    """
    Test function for computing a graph in a two islands toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df).astype(int)
    expected_source=[3,2,2,1,4,5,5,6,3,6]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9]
    expected_target=[1,1,3,0,5,4,6,4,2,5]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i])
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])


def test_two_islands_adj_matr_conn_comp_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for two islands of nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_two_islands_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for two islands of nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_two_islands_adj_conn_comp():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_two_islands_adj_matr_separation():
    """
    Test that, as expected, the adj matrix produced by write hypegraph, is splitted.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix, keeping the whole net, not only the connected component.
    THEN: The adjacency matrix is splitted in two parts.
    """
    isl_1_dim=4
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,exctract_largest_comp=False,write=False)
    adj_ordered=adj.toarray()
    users=[int(i) for i in users]
    for i in range(len(users)):
        for j in users:
            adj_ordered[users[i],users[j]]=adj[i,j]
    for i in range(isl_1_dim):
        for j in range(isl_1_dim-1):
            print(i,len(users)-j-1)
            assert adj_ordered[i,len(users)-j-1]==0
            assert adj_ordered[len(users)-j-1,i]==0

def test_two_islands_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_load_graph_two_islands():
    """
    Test function for loading a two islands graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/two_islands/two_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("two_islands/two_islands_head.npz"),pathlib.Path("two_islands/two_islands_tail.npz"),pathlib.Path("two_islands/two_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=(tail @ (head.transpose())).data
    adj_res=adj.data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_partition_leiden_two_islands_exctracted():
    """
    Test function for partitioning a two island graph with Leiden algorithm, computing only the largest connected component.

    GIVEN: A graph formed by two islands of nodes.
    WHEN: Partitioning the connected graph (only the connected component) using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("two_islands/two_islands_head.npz"),
               pathlib.Path("two_islands/two_islands_tail.npz"),
               pathlib.Path("two_islands/two_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames,)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in results:
        assert (i==0)

def test_partition_louvain_two_islands_unexctracted():
    """
    Test function for partitioning a two island graph with Louvain algorithm.

    GIVEN: A graph formed by two islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by two communities.
    """
    isl_1_dim=4
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("two_islands/comp_two_islands_head.npz"),
               pathlib.Path("two_islands/comp_two_islands_tail.npz"),
               pathlib.Path("two_islands/comp_two_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1)


def test_partition_leiden_two_islands_unexctracted():
    """
    Test function for partitioning a two island graph with Leiden algorithm.

    GIVEN: A graph formed by two islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by two communities.
    """
    isl_1_dim=4
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("two_islands/comp_two_islands_head.npz"),
               pathlib.Path("two_islands/comp_two_islands_tail.npz"),
               pathlib.Path("two_islands/comp_two_islands_usermap.csv.gz")]

    tail, head, usermap = load_graph(deadline,path,savenames,)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1)

######################################################
#THREE ISLANDS CASE CONNECTED#
###################################################### 

def test_three_islands_connected_comp_graph():
    """
    Test function for computing a graph in a three islands toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands_connected/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df).astype(int)
    expected_source=[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,0,3]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]
    expected_target=[1,2,0,2,0,1,4,5,3,5,3,4,7,8,6,8,6,7,3,6]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i])
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])

def test_three_islands_connected_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for three islands of nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands_connected/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_three_islands_connected_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands_connected/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_load_graph_three_islands_connected():
    """
    Test function for loading a three islands graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands_connected/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("three_islands_connected/three_islands_head.npz"),
               pathlib.Path("three_islands_connected/three_islands_tail.npz"),
               pathlib.Path("three_islands_connected/three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=(tail @ (head.transpose())).data
    adj_res=adj.data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_partition_louvain_three_islands_connected():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands_connected/comp_three_islands_head.npz"),
               pathlib.Path("three_islands_connected/comp_three_islands_tail.npz"),
               pathlib.Path("three_islands_connected/comp_three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1 if i<isl_1_dim+isl_2_dim else results[i]==2)


def test_partition_louvain_three_islands_connected_():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands_connected/comp_three_islands_head.npz"),
               pathlib.Path("three_islands_connected/comp_three_islands_tail.npz"),
               pathlib.Path("three_islands_connected/comp_three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1 if i<isl_1_dim+isl_2_dim else results[i]==2)

######################################################
#THREE ISLANDS CASE DISCONNECTED#
###################################################### 

def test_three_islands_comp_graph():
    """
    Test function for computing a graph in a three islands toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df).astype(int)
    expected_source=[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
    expected_target=[1,2,0,2,0,1,4,5,3,5,3,4,7,8,6,8,6,7]
    for i in range(len(retweets)):
        assert (retweets["source"][i]==expected_source[i])
        assert (retweets["hyperlink"][i]==expected_hyperlink[i])
        assert (retweets["target"][i]==expected_target[i])

def test_three_islands_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for three islands of nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    for i in range(len(users)):
        assert (adj.toarray()[i,i]==0)

def test_three_islands_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    for i in range(len(users)):    
        assert (np.sum(adj.toarray()[i])==expected_counts[i])

def test_three_islands_adj_compare():
    """
    Test function to compare the adjacenncy matrix if exctracting the connected component and if not.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions in two cases, using the whole graph or only the connected component.
    THEN: The connected component is smaller than the compleat graph, equal to one island.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=False)
    adj_exc,users_exc=write_hypergraph(retweets,deadline,path,write=False,exctract_largest_comp=True)
    adj_ordered=adj.toarray()
    users=[int(i) for i in users]
    for i in range(len(users)):
        for j in users:
            adj_ordered[users[i],users[j]]=adj[i,j]
    assert adj.nnz>adj_exc.nnz
    #return adj.toarray(),adj_exc.toarray()
    for i in range (isl_1_dim-1):
        for j in range(isl_1_dim-1):
            assert adj_ordered[i,j]==adj_exc.toarray()[i,j]

def test_three_islands_adj_matr_separation():
    """
    Test that, as expected, the adj matrix produced by write hypegraph, is splitted.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacency matrix, keeping the whole net, not only the connected component.
    THEN: The adjacency matrix is splitted in three parts.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,exctract_largest_comp=False,write=False)
    adj_ordered=adj.toarray()
    users=[int(i) for i in users]
    for i in range(len(users)):
        for j in users:
            adj_ordered[users[i],users[j]]=adj[i,j]
    for i in range(isl_1_dim):
        for j in range(len(users)-1):
            if (j>=isl_1_dim):
                assert adj_ordered[i,j]==0
                assert adj_ordered[j,i]==0
    for i in range(isl_2_dim):
        for j in range(len(users)-1):
            if (j>=isl_1_dim+isl_2_dim):
                assert adj_ordered[i+isl_1_dim,j]==0
                assert adj_ordered[j,i+isl_1_dim]==0

def test_load_graph_three_islands():
    """
    Test function for loading a three islands graph.

    GIVEN: The computed adjacency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/three_islands/three_islands.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("three_islands/three_islands_head.npz"),
               pathlib.Path("three_islands/three_islands_tail.npz"),
               pathlib.Path("three_islands/three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=(tail @ (head.transpose())).data
    adj_res=adj.data
    for i in range(len(adj_test)): 
        assert (adj_test[i]==adj_res[i])

def test_partition_louvain_compleat_three_islands():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands/comp_three_islands_head.npz"),pathlib.Path("three_islands/comp_three_islands_tail.npz"),pathlib.Path("three_islands/comp_three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1 if i<isl_1_dim+isl_2_dim else results[i]==2)


def test_partition_louvain_compleat_three_islands():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the whole graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands/comp_three_islands_head.npz"),
               pathlib.Path("three_islands/comp_three_islands_tail.npz"),
               pathlib.Path("three_islands/comp_three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in range(len(results)):
        assert (results[i]==0 if i<isl_1_dim else results[i]==1 if i<isl_1_dim+isl_2_dim else results[i]==2)

def test_partition_louvain_three_islands():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the connected component of graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands/three_islands_head.npz"),
               pathlib.Path("three_islands/three_islands_tail.npz"),
               pathlib.Path("three_islands/three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    for i in range(len(results)):
        assert (results[i]==0)


def test_partition_louvain_three_islands():
    """
    Test function for partitioning a three island graph with Louvain algorithm.

    GIVEN: A graph formed by three islands of nodes.
    WHEN: Partitioning the connected component of graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by three communities.
    """
    isl_1_dim=3
    isl_2_dim=3
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("three_islands/three_islands_head.npz"),
               pathlib.Path("three_islands/three_islands_tail.npz"),
               pathlib.Path("three_islands/three_islands_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    for i in range(len(results)):
        assert (results[i]==0)