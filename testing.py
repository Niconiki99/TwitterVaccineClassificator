import pandas as pd
import pytest
import numpy as np
import pathlib
from scipy import sparse
from build_graphs import load_data,compute_graph,write_hypergraph,load_graph
from build_communities import partition_core,simplify_community_struct
from configobj import ConfigObj 

def generate_metadata_full() -> (str, pd.Timestamp,dict):
    """
    Function to generate metadatas for the reading.

    Returns:
        Tuple[str, pd.Timestamp]: A tuple containing the path (str) and the deadline (pd.Timestamp) and the types of the columns (dict).
    """
    config= ConfigObj("config.txt")
    path=config["DIRS"]["TEST_PATH"]
    deadline=pd.Timestamp("2021-06-01" + "T00:00:00+02")
    dtype=config["READING_PARAMS"]["DF_FULL"]["dtype_df"]
    return path,deadline,dtype
    
def generating_metadata_example() -> (str, pd.Timestamp,dict):
    """
    Function to generate metadatas for the reading of exaples.

    Returns:
        Tuple[str, pd.Timestamp]: A tuple containing the path (str) and the deadline (pd.Timestamp) and the types of the columns (dict).
    """
    config= ConfigObj("config.txt")
    path=config["DIRS"]["TEST_PATH"]
    deadline=pd.Timestamp("2021-06-01" + "T00:00:00+02")
    dtype=config["READING_PARAMS"]["DF_FULL"]["dtype_example"]
    return path,deadline,dtype


def generating_simple_case() -> pd.DataFrame:
    """
    Function to generate a simple test dataset for connected component analysis.

    Returns:
        pd.DataFrame: A DataFrame containing the generated dataset.
    """
    #BUILDING AN EXAMPLE DATASET TO TEST THE CONNECTED COMPONENT ANALYSIS
    id=["0","1","2","3"]
    hyperlink=["0","1","2","3"]
    source=["3","0","1","2"]
    target=["1","2","3","0"]
    dict={"id":id,"source":source,"hyperlink":hyperlink,"target":target}
    retweet_simple=pd.DataFrame(dict)
    retweet_simple.set_index("id")
    return retweet_simple
    
def generate_simple_adj() -> (sparse.coo_matrix, sparse.coo_matrix):
    """
    Function to generate a simple adjacency matrix and an identity matrix.

    Returns:
        Tuple[sparse.coo_matrix, sparse.coo_matrix]: A tuple containing the adjacency matrix and the identity matrix.
    """
    x=[1,0,3,2,3,0]
    y_=[0,1,2,3,0,3]
    y=[0,1,2,3]
    adj=sparse.coo_matrix((np.ones(6),(x,y_)),shape=(4,4))
    id=sparse.coo_matrix((np.ones(4),(y,y)),shape=(4,4))
    return adj,id
########## TEST FUNCTIONS ##########
def test_load_data():
    """
    Test function for loading data.

    GIVEN: a path and a deadline timestamp generated by the function generate_metadata_full().
    WHEN: loading data using load_data() function.
    THEN: the function should return a pandas DataFrame.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path,dtype)
    assert isinstance(df, pd.DataFrame)


def test_compute_graph():
    """
    Test function for computing a graph.

    GIVEN: A DataFrame loaded from a CSV file using load_data().
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with the same number of nodes as the 'retweeted_status.id'
          column in the DataFrame after dropping NA values.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    df=load_data(deadline,path,dtype)
    assert len(compute_graph(df))==len(df["retweeted_status.id"].dropna())


def test_write_hypergraph_user():
    """
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a pandas Series for user_ids.
    """

    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path,dtype))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(users,pd.Series)

def test_write_hypergraph_matrix():
    """
    Test function for writing hypergraph.

    GIVEN: A graph computed with compute_graph() function.
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: the function should return a sparse csr_matrix for the adjancy matrix.
    """
    path,deadline,dtype=generate_metadata_full()
    path=path+"/df_full.csv.gz"
    retweet=compute_graph(load_data(deadline,path,dtype))
    matrix,users=write_hypergraph(retweet,deadline,write=False)
    assert isinstance(matrix,sparse.csr_matrix)


def test_write_hypergraph_simple_case():
    """
    Test function for writing hypergraph with a simple case.

    GIVEN: a simple test dataset generated by the function generating_simple_case().
    WHEN: writing a hypergraph using write_hypergraph() function.
    THEN: The risult has the signature (2,2).
    """

    retweet_simple=generating_simple_case()
    deadline=''
    matrix,users=write_hypergraph(retweet_simple,deadline,write=False)
    assert matrix.shape==(2,2)

def test_partition_core_type():
    """
    Test function for partitioning core with type checking.

    GIVEN: a graph loaded using load_graph().
    WHEN: partitioning core using partition_core() function.
    THEN: the function should return a pandas Series.
    """

    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    assert isinstance(partition_core(tail,head,usermap),pd.Series)
    assert isinstance(partition_core(tail,head,usermap,kind="leiden"),pd.Series)

def test_partition_core_simple_case_louvain():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with louvain algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3])).unique())==2
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2

def test_partition_core_simple_case_leiden():
    """
    Test function for partitioning core with a simple case.

    GIVEN: a simple adjacency matrix and an identity matrix generated by the function generate_simple_adj().
    WHEN: partitioning core using partition_core() function with leiden algorithm.
    THEN: the function should return a partition formed by two categories.
    """

    adj,id=generate_simple_adj()
    assert len(partition_core(adj,id,pd.Series([0,1,2,3]),kind="leiden").unique())==2


def test_simplify_community_struct_size_lv():
    """
    Test function for simplifying community structure by size with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    comm_size=50
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap),comm_size)
    assert (i<comm_size+1 for i in simplified_com.value_counts().sort_values(ascending=False))

def test_simplify_community_struct_size_ld():
    """
    Test function for simplifying community structure by size with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the size at 50.
    THEN: the resulting simplified community structure should have communities with sizes less than or equal to 50.
    """
    comm_size=50
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    simplified_com=simplify_community_struct(partition_core(tail,head,usermap,kind="leiden"),comm_size)
    assert (i<comm_size+1 for i in simplified_com.value_counts().sort_values(ascending=False))

def test_simplify_community_coverage_lv_40():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """
    coverage=0.4
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_ld_40():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 40%.
    THEN: the resulting simplified community structure should cover at least 40% of the original communities.
    """
    coverage=0.4
    path,deadline,dtype=generate_metadata_full()
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_lv_90():
    """
    Test function for simplifying community structure by coverage with Louvain.

    GIVEN: a partitioning core using partition_core() function with louvain algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline,dtype=generate_metadata_full()
    coverage=0.9
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap)
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)

def test_simplify_community_coverage_ld_90():
    """
    Test function for simplifying community structure by coverage with Leiden.

    GIVEN: a partitioning core using partition_core() function with leiden algorithm.
    WHEN:  simplifying community structure using simplify_community_struct() function, fixing the coverage at 90%.
    THEN: the resulting simplified community structure should cover at least 90% of the original communities.
    """
    path,deadline,dtype=generate_metadata_full()
    coverage=0.9
    tail, head, usermap = load_graph(deadline,path)
    coms=partition_core(tail,head,usermap,kind="leiden")
    simplified_com=simplify_community_struct(coms,coverage)
    counts=coms.value_counts().sort_values(ascending=False)
    coverage=np.sum(counts.iloc[:len(np.unique(simplified_com.values))-1].values)/len(coms)
    assert (coverage>coverage-0.01)
    
def test_connected_comp_graph():
    """
    Test function for computing a graph in a connected toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    rewteets=compute_graph(df)
    expected_source=[0,0,0,0,0,1,1,2,2,3,3,3]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11]
    expected_target=[1,2,3,1,2,3,2,1,0,0,1,2]
    assert (rewteets["source"][i]==expected_source[i] for i in range(len(rewteets)))
    assert (rewteets["hyperlink"][i]==expected_hyperlink[i] for i in range(len(rewteets)))
    assert (rewteets["target"][i]==expected_target[i] for i in range(len(rewteets)))

def test_connected_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for connected nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacy matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    assert (adj.toarray()[i,i]==0 for i in range(len(retweets.source.unique())))

def test_con_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    assert (np.sum(adj.toarray[i])==expected_counts[i] for i in range(len(users)))

def test_load_graph_connected():
    """
    Test function for loading a connected graph.

    GIVEN: The computed adjency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix and usermap.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    savenames=[pathlib.Path("connected_head.npz"),pathlib.Path("connected_tail.npz"),pathlib.Path("connected_usermap.csv.gz")]
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    tail, head, usermap = load_graph(deadline,path,savenames)
    adj_test=tail @ (head.transpose())
    assert (adj_test).nnz==adj.nnz

def test_partition_louvain_connected():
    """
    Test function for partitioning a connected graph with Louvain algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("connected_head.npz"),pathlib.Path("connected_tail.npz"),pathlib.Path("connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    assert (i==0 for i in results)


def test_partition_leiden_connected():
    """
    Test function for partitioning a connected graph with Leiden algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("connected_head.npz"),pathlib.Path("connected_tail.npz"),pathlib.Path("connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    assert (i==0 for i in results)

def test_comp_connected_comp_graph():
    """
    Test function for computing a graph in a completely connected toy model.

    GIVEN: A DataFrame loaded from a CSV file using load_data(), coming from a known configuration.
    WHEN: computing a graph using compute_graph() function.
    THEN: the function should return a graph with expected values for the columns.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    rewteets=compute_graph(df)
    expected_source=[0,0,0,0,0,1,1,2,2,3,3,3]
    expected_hyperlink=[0,1,2,3,4,5,6,7,8,9,10,11]
    expected_target=[1,2,3,1,2,3,2,1,0,0,1,2]
    assert (rewteets["source"][i]==expected_source[i] for i in range(len(rewteets)))
    assert (rewteets["hyperlink"][i]==expected_hyperlink[i] for i in range(len(rewteets)))
    assert (rewteets["target"][i]==expected_target[i] for i in range(len(rewteets)))

def test_comp_connected_adj_matr_diag():
    """
    Test function for verifying diagonal elements of the adjacency matrix for completly connected nodes.

    GIVEN: A simple dataframe.
    WHEN: Computing the adjacy matrix.
    THEN: The diagonal elements of the adjacency matrix should be zero.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    assert (adj.toarray()[i,i]==0 for i in range(len(retweets.source.unique())))

def test_comp_con_adj():
    """
    Test function for verifying adjacency matrix consistency with source counts.

    GIVEN: A simple dataframe.
    WHEN: Computing the graph and writing hypergraph using compute_graph() and write_hypergraph() functions.
    THEN: The sum of row elements in the adjacency matrix should be equal to the number of retweets from each source.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    expected_counts=[len(retweets[retweets["source"]==str(i)]) for i in users]
    assert (np.sum(adj.toarray[i])==expected_counts[i] for i in range(len(users)))

def test_load_graph_comp_connected():
    """
    Test function for loading a completly connected graph.

    GIVEN: The computed adjency matrix.
    WHEN: Loading the connected graph data using load_graph() function.
    THEN: The loaded graph data (tail, head, usermap) should match the computed adjacency matrix.
    """
    path,deadline,dtype=generating_metadata_example()
    name=path+"/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    savenames=[pathlib.Path("comp_connected_head.npz"),pathlib.Path("comp_connected_tail.npz"),pathlib.Path("comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    users=[int(i) for i in users]
    usermap=[int(i) for i in usermap]
    adj_test=tail @ (head.transpose())
    assert (adj_test).nnz==adj.nnz

def test_simmetry_comp_con():
    path,deadline,dtype=generating_metadata_example()
    name=path+"/comp_connected.csv.gz"
    df=load_data(deadline,name,dtype)
    retweets=compute_graph(df)
    adj,users=write_hypergraph(retweets,deadline,path,write=False)
    assert(adj.transpose().nnz==adj.nnz)



def test_partition_louvain_comp_connected():
    """
    Test function for partitioning a completly connected graph with Louvain algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Louvain algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("comp_connected_head.npz"),pathlib.Path("comp_connected_tail.npz"),pathlib.Path("comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap)
    assert (i==0 for i in results)


def test_partition_leiden_comp_connected():
    """
    Test function for partitioning a connected graph with Leiden algorithm.

    GIVEN: A graph formed by nodes all connected.
    WHEN: Partitioning the connected graph using partition_core() function with Leiden algorithm.
    THEN: The resulting partitions should be formed by only one community.
    """
    path,deadline,dtype=generating_metadata_example()
    savenames=[pathlib.Path("comp_connected_head.npz"),pathlib.Path("comp_connected_tail.npz"),pathlib.Path("comp_connected_usermap.csv.gz")]
    tail, head, usermap = load_graph(deadline,path,savenames)
    results=partition_core(tail,head,usermap,kind="leiden")
    assert (i==0 for i in results)





